---
title: "Practical Machine Learning Course Project"
author: "Alex Sickert"
date: "14 July 2016"
output: html_document
---




```{r include=FALSE, echo=TRUE, message=FALSE}

#knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(randomForest)


```

## Intruduction


## Load Data


```{r}

train_data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", header=TRUE, sep=",", na.strings=c("NA",""))


summary(train_data)
head(train_data)

```

## Clean Data

Many columns contain NA data. We remove these columns to have a feature set that is more meaningful.

```{r}

#colnames(train_data)

train_data_feature_set_columns <- colnames(train_data[colSums(is.na(train_data)) == 0])[-(1:7)]

model_data <- train_data[train_data_feature_set_columns]


```

## Chosing approach 

There are various approaches how to create prediction models. For this project I use random forest. Because it tends to be very accurate. On the other hand it is slow. But speed it not a critical factor for this assignment. 

## Create partitions

First I split the data in a training and test data set. 

```{r}

partition <- createDataPartition(y=model_data$classe, p=0.7, list=FALSE )
training <- model_data[partition,]
testing <- model_data[-partition,]


```

Then I create the prediction model using the training data set. This step takes a lot of time for calulation. On my computer more than 1 hour. 

```{r}

modFit <- randomForest(classe ~ .,   data=training)

importance(modFit) # importance of each predictor


```

## Create predictions and evaluate outcome

Now we apply the model to the train and test data and create a confustion matrix which allows us understanding who well the model predicts the classificaton. 

First we apply the model to the training dataset. Here it should work verz accuratly. But it could be subject to overfitting. 

```{r}


predictions1 <- predict(modFit, newdata=training)
confusionMatrix(predictions1,training$classe)

```


As a next step we apply it to the testing set. The prediction should be a bit worse but as the prediction with the training set is often subject to overfitting. 

```{r}

predictions2 <- predict(modFit, newdata=testing)
confusionMatrix(predictions2,testing$classe)


```



## Apply the model to the test data and process it with provided code

Finally I use the model for predicting the classes of the dataset that was provided. I also use a code nittped provided by Coursera. 

```{r}

quizz_data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", header=TRUE, sep=",", na.strings=c("NA",""))

train_data_feature_set_columns

quizz_data <- quizz_data[train_data_feature_set_columns]
quizz_data <- quizz_data[, -classe]

result <- predict(modFit, newdata=quizz_data)

result

```

After submitting the result to the quizz it turns out at the result is correct.
